## 概率论

1927年10月召开的第五次索尔维会议可能是最著名的一次索尔维会议，世界上最主要的物理学家聚集在一起讨论量子理论的相关问题。这次会议也被视为是爱因斯坦和波尔的的终极论战，前者以“上帝不会掷骰子”的观点反对海森堡的不确定性原理，后者则以“不要告诉上帝怎么做事”的观点对爱因斯坦进行了强烈反驳。在这次会议之后，越来越多的人开始接受和相信随机性和不确定性支配着这个世界，而这些随机性也不能通过人为的努力使其完全确定下来。当然，处理这些具有不确定性的问题，概率论和统计学是最强有力的工具。

<img src="res/Solvay.jpg" style="zoom:35%;">

### 基本概念

1. 在一定条件下，对事物或现象进行的观察或实验叫做**试验**（*trails*），试验的结果叫做**事件**（*event*）。
2. 随机事件（*random event*）：在一定条件下可能发生也可能不发生的事件，即结果具有偶然性的事件，通常用大写字母$\small{A}$、$\small{B}$、$\small{C}$等来表示。
3. 必然事件（*certain event*）和不可能事件（*impossible event*）：必然事件是在一定条件下每次试验一定出现的事件；不可能事件是在一定条件下每次试验一定不出现的事件。
4. 基本事件（*elementary event*）：如果一个事件不能拆分为两个或更多的事件，则将该事件称为基本事件或简单事件。在一次试验中，只能观察到一个且仅有一个基本事件。
6. 样本空间（*sample space*）：一个试验中所有的基本事件（一切可能的结果）组成的集合，通常记为$ \Omega $。

  - 抛一枚硬币的样本空间：$\small{\Omega = \{ 正, 反 \}}$。
  - 抛两枚硬币的样本空间：$\small{\Omega = \{ (正, 正), (正, 反), (反, 正), (反, 反) \}}$。
  - 掷一颗色子的样本空间：$\small{\Omega = \{1, 2, 3, 4, 5, 6\}}$。
7. 随机试验（*random trials*）：在相同条件下对某种随机事件进行观测的试验。随机试验满足三个特点：

    - 可以在相同条件下重复的进行。
    - 每次试验的结果不止一个，事先可以明确指出全部可能的结果。
    - 重复试验的结果以随机的方式出现（事先不确定会出现哪个结果）。

### 概率的定义

概率（*probability*）是对事件在试验中出现的可能性大小的一种度量，事件$\small{A}$出现的可能性通常记为$\small{P(A)}$，它是一个取值范围在0到1之间的值。

1. 古典概型：如果试验的结果是有限的，而且各个结果出现的可能性是相同的，那么可以用下面的方式来定义概率。

$$
P(A) = \frac{事件A所包含的基本事件的个数}{样本空间中所包含的基本事件的个数}
$$

2. 统计定义：在相同条件下进行$ n $次随机试验，事件$\small{A}$出现了$\small{m}$次，则$\small{\frac{m}{n}}$称为事件$\small{A}$发生的频率。随着试验次数$\small{n}$的增加，事件$\small{A}$发生的频率会在某个常量$\small{p}$上下波动，且波动的幅度越来越小，那么这个频率的稳定值就是事件$\small{A}$的概率。大家可以看看下表中的几位大佬曾经做过的抛硬币试验，相信就不难理解概率的统计定义。

    |    试验者    | 抛掷次数（n） | 正面朝上次数（m） | 正面朝上频率（m/n） |
    | :----------: | :-----------: | :---------------: | :-----------------: |
    |    德摩根    |     2048      |       1061        |       0.5181        |
    |     布冯     |     4040      |       2048        |       0.5069        |
    |     费勒     |     10000     |       4979        |       0.4979        |
    |    皮尔逊    |     12000     |       6019        |       0.5016        |
    |    皮尔逊    |     24000     |       12012       |       0.5005        |
    | 罗曼诺夫斯基 |     80640     |       39699       |       0.4932        |

    概率的统计定义能够成立的原因是大数定律（*law of large numbers*），大数定律简单的描述就是：**样本数量越多，样本的算术平均值就有越高的概率接近期望值**。大数定律很重要，因为它揭示了一些随机事件的均值的长期稳定性。回到上面的抛硬币试验，我们抛一枚硬币，硬币落下后哪一面朝上是偶然的，但当我们抛硬币的次数足够多（如上万次甚至几十万次）后，我们就会发现，硬币每一面向上的次数都是总次数的二分之一，也就是说**偶然之中包含着必然**。我们再举一个掷骰子的例子，抛掷一颗均匀的骰子，1到6的点数应等概率出现，所以每次扔出骰子后，出现点数的期望值是3.5，计算方法如下所示。
    $$
    \frac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5
    $$
    根据大数定理，如果多次抛掷骰子，随着抛掷次数的增加，样本平均值应该接近3.5，如下图所示。试验开始的时候，样本均值可能会在3.5的上下波动，但是随着试验次数的增加，波动会越来越小，样本均值收敛于期望值。

    <img src="res/law_of_large_numbers.png" style="zoom:35%;">

    > **说明**：上图来自于维基百科，我们可以在程序中生成1~6均匀分布的随机数来模拟掷色子，然后计算出点数的平均值，观察它是否收敛于3.5。使用 Python 语言的三方库 matplotlib，我们也能够很容易画出上面的图形。

    大数定律有以下几种表述形式：

    - 弱大数定律（辛钦定理）：样本均值依概率收敛于期望值，即对于任意正数$\small{\varepsilon}$，有：$\small{\lim_{n \to \infty}P(|\bar{X_n}-\mu|>\varepsilon)=0}$。
    - 强大数定律：样本均值以概率1收敛于期望值，即：$\small{P(\lim_{n \to \infty}\bar{X_n}=\mu)=1}$。
    - 伯努利大数定律：在$\small{n}$重伯努利试验中，事件$\small{A}$发生的次数为$\small{n_{a}}$，事件$\small{A}$在每次试验中发生的概率为$\small{p}$，$\small{\frac{n_a}{n}}$代表试验中事件$\small{A}$发生的频率，则对于任意正数$\small{\varepsilon > 0}$，有：$\small{\lim_{n \to \infty}P\{|\frac{n_a}{n} - p| < \varepsilon\} = 1}$。

    >**说明**：$\small{n}$重伯努利试验在后续的章节中会进行介绍，不理解的跳过这里就可以了。

3. 主观定义：概率的主观定义，也称为主观概率，是基于个人信念或意见来定义的概率。对于一些无法重复的试验，只能通过主观经验（个人掌握的信息）对事件发生的可能性做出判断。主观概率是因人而异的，不同的人对同一事件可能有不同的概率评估。例如，一个气象学家认为某地明天下雨的概率是70%，而一位农民伯伯认为这个概率是80%。统计学中的贝叶斯学派就强调利用先验知识（主观经验）结合观测数据来更新对未知参数的认知，这种方法论在医学、金融、人工智能等诸多领域都有广泛应用。

### 复合事件

有的时候，我们需要讨论两个或两个以上的事件的概率。给定事件$\small{A}$和事件$\small{B}$，可以用$\small{P(A \cap B)}$来表示事件$\small{A}$和事件$\small{B}$同时发生的概率，用$\small{P(A \cup B)}$来表示事件$\small{A}$或事件$\small{B}$发生的概率。例如，事件$\small{A}$表示患某种疾病，事件$\small{B}$表示筛查结果呈阳性，那么绿色区域$\small{A \cap B}$表示患有某疾病且筛查结果呈阳性（真阳性）；蓝色区域表示患有某种疾病但筛查结果为阴性（假阴性）；黄色区域表示未患有某种疾病但筛查结果为阳性（假阳性）；白色区域$\small{A^{\tiny{C}} \cap B^{\tiny{C}}}$表示未患某种疾病且筛查结果为阴性（真阴性）；如下图所示。

<img src="res/compound_events.png" style="zoom:30%;">

1. 加法定理：我们可以用下面的公式来计算$\small{P(A \cup B)}$的概率：
    $$
    P(A \cup B) = P(A) + P(B) - P(A \cap B)
    $$

2. 互斥事件：当两个事件不能同时发生时，我们称之为互斥事件（*mutually exclusive*），这意味着两个事件的交集是空集，即$\small{A \cap B = \emptyset}$，也可以表示为$\small{P(A \cap B) = 0}$，那么：

$$
P(A \cup B) = P(A) + P(B)
$$

3. 互补事件：事件$\small{A}$的对立面称为事件$\small{A}$的互补事件，通常用$\small{A^{\tiny{C}}}$或$\small{\bar{A}}$来表示，很显然：
    $$
    P(\bar{A}) = 1 - P(A)
    $$
    

### 条件概率

**条件概率**是指事件$\small{A}$在事件$\small{B}$发生的条件下发生的概率，通常记为$\small{P(A|B)}$。设$\small{A}$与$\small{B}$为样本空间$\small{\Omega}$中的两个事件，其中$\small{P(B) \gt 0}$，那么在事件$\small{B}$发生的条件下，事件$\small{A}$发生的条件概率为$\small{{P(A|B)=\frac{P(A \cap B)}{P(B)}}}$，结合上面的韦恩图来理解这个计算公式应该是非常直观的。特别的，当$\small{P(B)=0}$时，规定$\small{P(A|B) = 0}$。

1. 独立事件：两个事件彼此不影响对方的发生，那么两个事件是相互独立的，有：
    $$
    P(A|B) = P(A), \quad P(B|A) = P(B)
    $$

2. 乘法定理：我们可以用下面的公式计算$\small{P(A \cap B)}$。
    $$
    P(A \cap B) = P(A|B) \cdot P(B)
    $$

3. 全概率公式：我们将上面公式中的事件$\small{B}$换成样本空间$\small{\Omega}$，它由$\small{B_1, B_2, \cdots, B_n}$构成的，于是有：
    $$
    \begin{align}
    P(A) &= \sum_{i=1}^{n}P(A \cap B_i) \\
    &= \sum_{i=1}^{n}P(A|B_i)P(B_i)
    \end{align}
    $$
    
4. 贝叶斯定理：显然，当$\small{P(A) \neq P(B)}$时，$\small{P(A|B)}$和$\small{P(B|A)}$也是不同的。然而，这两者是有确定的关系的，**贝叶斯定理**就是对这种关系的陈述，如下所示：
    $$
    P(A|B)=\frac{P(B|A)}{P(B)}P(A)
    $$
    贝叶斯定理非常简单也极为直观，大家可以尝试着把等号右边的$\small{P(B)}$放到等号的左边去，有：
    $$
    P(A|B) \cdot P(B) = P(B|A) \cdot P(A)
    $$
    等号的两边都是$\small{P(A \cap B)}$。

    在贝叶斯定理中，我们将$\small{P(A)}$称为事件$\small{A}$的先验概率，可以将其理解为已知的事实或是主观的经验；$\small{P(B)}$是事件$\small{B}$的先验概率（也称边缘概率），$\small{P(B|A)}$是已知事件$\small{A}$发生的前提下，事件$\small{B}$发生的条件概率，我们称其为事件$\small{B}$的似然性；通过贝叶斯定理，我们可以计算出$\small{P(A|B)}$，计算出的概率我们称之为事件$\small{A}$的后验概率。贝叶斯定理告诉我们，你可以从主观经验或已知的概率出发，通过获取数据（收集证据），对主观经验或已知的概率在特定条件下进行修正，这种方法会帮助我们推导出未知的真相。这个过程跟人类大脑思考问题的方式非常类似，也是很多人工智能算法的基础。

#### 例子

公司只有两个输出能力完全相同的软文写手孙小美和王大锤，你对孙小美75%的软文非常满意，对王大锤40%的软文非常满意。有一天你看到一篇没有署名的软文，你对它感到非常满意，那么这篇软文来自于王大锤的概率是多少呢？

我们用$\small{A_2}$表示软文来自王大锤，用$\small{B}$表示对软文非常满意，我们需要计算的是$\small{P(A_2|B)}$。显然$\small{P(A_2) = 0.5}$，而根据题目的叙述，$\small{P(B|A_2) = 0.4}$，只要能计算出$\small{P(B)}$，就可以根据贝叶斯定理计算出$\small{P(A_2|B)}$。我们可以利用全概率公式计算出$\small{P(B)}$，其中$\small{A_1}$表示软文来自于孙小美，由于公司只有两个写手且输出能力相同，所以$\small{P(B)}$的计算方法如下所示：
$$
\begin{align}
P(B) &= P(B|A_1)P(A_1) + P(B|A_2)P(A_2) \\
&= 0.75 \times 0.5 + 0.4 \times 0.5 \\
&= 0.575
\end{align}
$$
那么，软文来自于王大锤的概率为：
$$
\begin{align}
P(A_2|B) &= \frac{P(B|A_2)}{P(B)}P(A_2) \\
&= \frac{0.4}{0.575} \times 0.5 \approx 0.35
\end{align}
$$
我们可以用全概率公式来解决之前提出的“三门问题”，证明换门获得车的概率比不换门更高。如果参赛者第一次选中了车（概率为$\small{\frac{1}{3}}$），那么换门之后获得车的概率为0，如果参赛者第一次选中了羊（概率为$\small{\frac{2}{3}}$），那么换门后获得车的概率为1。我们用$\small{A}$表示参赛者获得车，根据全概率公式，有：
$$
P(A) = \frac{1}{3} \times 0 + \frac{2}{3} \times 1 = \frac{2}{3}
$$
很显然，换门能够让获得车的概率从原来的$\small{\frac{1}{3}}$上升为$\small{\frac{2}{3}}$，获得车的概率提升了一倍，那肯定是要换门的。有人认为换门后获得车的概率并没有发生变化，那是因为对题目的解读就出现了问题。题目中说，“当参赛者选定一扇门但还没有打开它的时候，知道门后情形的节目主持人会开启剩下两扇门中的其中一扇，露出其中一只山羊”，请注意这个地方的叙述，主持人并不是随意的打开了一扇门刚好露出一只羊，而是知道门后面的情形，打开了后面有羊的一扇门。按照这个理解，上面的全概率公式才是对相应概率的正确解读。

### 随机变量

在相同的条件下，如果每次试验可能出现这样或那样的结果，我们对随机事件进行数量化，用$\small{X}$表示所有可能的事件，也就是说$\small{X}$可以有不同的取值，用$\small{P(X)}$表示$\small{X}$取不同的值时对应事件发生的概率，如果我们把$\small{P(X)}$称作概率函数（*probability function*），那么这里的$\small{X}$就称为概率函数$\small{P(X)}$的随机变量（*random variable*）。简单的说，随机变量就是一次试验结果的数值性描述。

<img src="res/probability_2_2.png" style="zoom:40%;">

下面是一些随机变量的例子：

1. 掷一颗骰子，出现的点数是一个随机变量。
2. 检查100件产品，残次品的数量是一个随机变量。
3. 某电商网站今年的销售额是一个随机变量。

简单的说，随机变量的值是需要通过试验来进行确认的。随机变量根据其值是否可列分为：

- 离散型随机变量（*discrete random variable*）：随机变量$\small{X}$所有的取值是有限的或可列，例如：一批产品中取到残次品的个数、客服系统单位时间内收到电话呼叫的次数等。

- 连续型随机变量（*continuous random variable*）：随机变量$\small{X}$所有的取值是无限的且不可列，例如：一批电子元器件的寿命、测量误差等。

    > **说明**：如果离散型随机变量的取值非常庞大时，可以近似看做连续型随机变量。
    
    <img src="res/probability_3_3.png" style="zoom:50%;">

如上图2所示，由于连续型随机变量可以取某个区间或整个实数轴上任意的值，我们不能够像离散型随机变量那样列出每一个值及其对应的概率，我们可以定义概率密度函数（*probability density function*）和累积分布函数（*cumulative distribution function*）来描述其概率。概率密度函数满足以下两个条件：
$$
f(x) \ge 0
$$

$$
\int_{-\infty}^{+\infty}f(x)dx = 1
$$

需要注意的是，$\small{f(x)}$并不是一个概率，在指定范围对$\small{f(x)}$进行积分的结果才是概率，例如随机变量$\small{X}$取值在$\small{a}$和$\small{b}$之间的概率是：
$$
P(a \lt X \lt b) = \int_{a}^{b}f(x)dx
$$
对于连续型随机变量，由于不可能去罗列出每一个值出现的概率，为此我们需要引入分布函数的概念，如下所示：
$$
F(x) = P\{X \le x\} = \int_{-\infty}^{x}f(t)dt
$$

如果将$\small{X}$看成是数轴上的随机坐标，上面的分布函数表示了$\small{X}$落在区间$\small{(-\infty, x)}$中的概率。很显然，分布函数有以下性质：

1. $\small{F(x)}$是一个单调不减的函数；
2. $\small{0 \le F(x) \le 1}$，且$\small{F(-\infty) = \lim_{x \to -\infty} F(x) = 0}$， $\small{F(\infty) = \lim_{x \to \infty} F(x) = 1}$；
3. $\small{F(x)}$是右连续的。

按照分布函数的定义，上面的$\small{P(a \lt X \lt b)}$也可以写成：
$$
P(a \lt X \lt b) = F(b) - F(a)
$$

### 期望和方差

为了全面了解随机变量$\small{X}$的概率性质，最好的情况是知道$\small{X}$的概率分布。但在现实问题中，$\small{X}$的概率分布往往不好确定，但是在很多场景下，我们也不需要了解$\small{X}$所有的概率性质，只需要知道它某些数字特征就够了。在随机变量的各种数字特征中，最为重要的就是（数学）期望和方差。

1. 期望：期望是表示随机变量平均水平或集中程度的数字特征，是随机变量按照概率的加权平均值，记为$\small{E(X)}$。

    - 对于离散型随机变量$\small{X}$，若$\small{\sum_{i=1}^{\infty} x_ip_i}$收敛，那么它就是随机变量$\small{X}$的期望。
        $$
        E(X) = \sum_{i=1}^{\infty} x_ip_i
        $$

    - 对于连续型随机变量$\small{X}$，其概率密度函数为$\small{f(x)}$，若$\small{\int_{-\infty}^{\infty}xf(x)dx}$收敛，那么它就是随机变量$\small{X}$的期望。
        $$
        E(x) =  \int_{-\infty}^{\infty}xf(x)dx
        $$

    > **思考**：掷一颗色子，掷出点数的期望是多少？

2. 方差：方差是表示随机变量变异程度或离散程度的数字特征，它是随机变量与其数学期望离差的平均水平。对于随机变量$\small{X}$，若$\small{E[X - E(X)]^2}$存在，则称$\small{E[X - E(X)]^2}$为$\small{X}$的方差，常用记为$\small{D(X)}$或$\small{V(X)}$。

    - 离散型随机变量$\small{X}$的方差：
        $$
        V(X) = \sum_{i=1}^{\infty} [x_i - E(X)]^2p_i
        $$

    - 连续型随机变量$\small{X}$的方差：
        $$
        V(X) = \int_{-\infty}^{\infty} [x - E(X)]^2f(x)dx
        $$
    
    > **思考**：掷一颗色子，掷出点数的方差是多少？

3. 期望与方差的性质：
    - 对于任意两个随机变量$\small{X_1}$和$\small{X_2}$，则有$\small{E(X_1 + X_2) = E(X_1) + E(X_2)}$。
    - 若$\small{X}$是随机变量，$\small{a}$和$\small{b}$是任意常量，则有$\small{E(aX + b) = aE(X) + b}$和$\small{V(aX + b) = a^{2}V(X)}$。
    - 若随机变量$\small{X_1}$和$\small{X_2}$独立，则有$\small{V(X_1 + X_2) = V(X_1) + V(X_2)}$。

### 离散型随机变量的分布

1. 伯努利分布（*Bernoulli distribution*）：又名**两点分布**或者**0-1分布**，是一个离散型概率分布。若伯努利试验（**只有两种可能结果的单次随机试验**）成功，则随机变量取值为1。若伯努利试验失败，则随机变量取值为0。记其成功概率为$\small{p (0 \le p \le 1)}$，则失败概率为$\small{1-p}$，则概率质量函数为：
    $$
    {P(X=k)=p^{k}(1-p)^{1-k}=\left\{{\begin{matrix}p & (k=1)\\1-p & (k=0)\\\end{matrix}}\right.}
    $$

2. 二项分布（*binomial distribution*）：二项分布描述了$\small{n}$重伯努利试验中，如果每次试验成功的概率为$\small{p}$，正好有$\small{k}$次成功的概率分布。一般地，如果随机变量$\small{X}$服从参数为$\small{n}$和$\small{p}$的二项分布，记为$\small{X \sim B(n,p)}$，其概率质量函数为：
    $$
    P(X=k) = {n \choose k}p^k(1-p)^{n-k}
    $$

    > **注意**：上面提到的$ n $重伯努利试验需要满足以下要求：①试验的结果只有两种：成功或失败；②试验的结果是独立的，彼此不影响；③试验重复次数是固定的$n$；④每次试验成功的概率都是$p$。在上面的公式中，$n \choose k$表示$ n $选$ k $的组合数，国内的教科书通常记为$ C_{n}^{k} $，计算公式为$ \frac{n!}{k!(n-k)!} $。Python中，可以通过`math`模块的`comb`函数计算组合数的值；可以通过三方库 numpy 中的`random.binomial`函数产生二项分布的随机数；可以通过三方库 scipy 中的`stats.binom.pmf`函数计算二项分布的概率。Excel 中，可以通过`BINOM.DIST`函数计算二项分布的概率。

    <img src="res/binomial_distribution.png" style="zoom:35%;">

    很显然，伯努利分布就是二项分布在$ n=1 $时的特例。二项分布的期望和方差分别是：
    $$
    \begin{align}
    E(X) &= np \\
    V(X) &= np(1-p)
    \end{align}
    $$
    
3. 泊松分布（*Poisson distribution*）：泊松分布通常用来描述指定的时间范围或指定的面积（体积）内随机事件发生次数的概率分布，例如：某台服务器在某一小时内接收到服务请求的次数、某段单位时间内汽车站台的候客人数、某种机器每月出现故障的次数、某区域每年发生自然灾害的次数、DNA序列的变异数、放射性原子核的衰变数、保险公司每天收到死亡声明的份数等。泊松分布的概率质量函数如下所示：
    $$
    P(X=k)=\frac{\lambda^k}{k!} \cdot e^{-\lambda}
    $$
    其中，参数$\small{\lambda}$是单位时间或单位面积（体积）内事件的平均值。

    <img src="res/poisson_distribution.png" style="zoom:60%;">

    > **说明**：上面两张图都来自于维基百科，我们也可以用 Python 的三方库 matplotlib 来绘制上面的图形，需要代码的小伙伴可以在评论区留言。

    泊松分布的期望和方差分别为：
    $$
    \begin{align}
    E(X) &= \lambda \\
    V(X) &= \lambda
    \end{align}
    $$
    在没有计算机的年代，由于二项分布的运算量太大，为了减少运算量，数学家们通常用泊松分布作为二项分布的近似。当二项分布的$\small{n}$很大，$\small{p}$很小的时候，我们可以令$\small{\lambda = np}$，然后用泊松分布的概率质量函数计算概率来近似二项分布的概率。例如：某批集成电路的次品率为0.15%，随机抽取1000块该集成电路，求次品数分别为0、1、2、3、4、5的概率。很显然，这里提到的场景是一个$ n $重伯努利试验，由于$\small{n = 1000}$，$\small{p=0.0015}$，可以用泊松分布做近似，这里大家也能够很直观的感受到泊松分布的计算量是远远小于二项分布的，下面的表格是二项分布和泊松分布结果的对照。

    > **说明**：使用 Python 语言，可以通过三方库 scipy 中的`stats.poisson.pmf`函数计算泊松分布的概率。Excel 中，可以通过`POISSON.DIST`函数计算泊松分布的概率。
    
    | $\small{P(X = k)}$ | $\small{{n \choose k}p^k(1-p)^{n-k}}$ | $\small{\frac{e^{-\lambda}\lambda^k}{k!}}$ |
    | :----------------: | :-----------------------------------: | :----------------------------------------: |
    | $\small{P(X = 0)}$ |              0.22287903               |                 0.22313016                 |
    | $\small{P(X = 1)}$ |              0.33482077               |                 0.33469524                 |
    | $\small{P(X = 2)}$ |              0.25124133               |                 0.25102143                 |
    | $\small{P(X = 3)}$ |              0.12555776               |                 0.12551072                 |
    | $\small{P(X = 4)}$ |              0.04701343               |                 0.04706652                 |
    | $\small{P(X = 5)}$ |              0.01406872               |                 0.01411996                 |
    
    下面是$\small{n \to \infty}$时，二项分布获得$\small{k}$次成功的概率极限的计算，我们令$\small{p = \frac{\lambda}{n}}$，有：
    $$
    \begin{align}
    \lim_{n \to \infty}{{n \choose k}(\frac{\lambda}{n})^{k}(1 - \frac{\lambda}{n})^{n-k}} 
    &= \lim_{n \to \infty}{\frac{n!}{k!(n-k)!}\frac{\lambda^{k}}{n^{k}}(1 - \frac{\lambda}{n})^{n}(1 - \frac{\lambda}{n})^{-k}} \\
    &= \lim_{n \to \infty}{\frac{\lambda^{k}}{k!} \frac{n(n - 1)(n - 2)\cdots(n - (k - 1))}{n \times n \times \cdots \times n} (1 - \frac{\lambda}{n})^{n}(1 - \frac{\lambda}{n})^{-k}}
    \end{align}
    $$
    其中，
    $$
    \lim_{n \to \infty}\frac{n(n - 1)(n - 2)\cdots(n - (k - 1))}{n \times n \times \cdots \times n} = 1 \\
    \lim_{n \to \infty}(1 - \frac{\lambda}{n})^{-k} = 1
    $$
    已知，
    $$
    \lim_{x \to \infty} (1 + \frac{1}{x})^{x} = e
    $$
    于是，
    $$
    \lim_{n \to \infty}(1 - \frac{\lambda}{n})^{n} = \lim_{n \to \infty}(1 + \frac{1}{-\frac{n}{\lambda}})^{-\frac{n}{\lambda} \cdot -\lambda} = e^{-\lambda}
    $$
    因此，
    $$
    \lim_{n \to \infty}{{n \choose k}(\frac{\lambda}{n})^{k}(1 - \frac{\lambda}{n})^{n-k}} = \frac{\lambda^{k}}{k!} \cdot e^{-\lambda}
    $$
    
4. 几何分布（*geometric distribution*）：几何分布通常用来描述在伯努利试验中，获得一次成功需要的试验次数。如果每次试验成功的概率为$\small{p}$，那么$\small{k}$次试验，第$\small{k}$次才得到的成功的概率是：$\small{P(X=k) = (1-p)^{k-1}p}$，其中$\small{k=1, 2, 3, \cdots}$。若随机变量$\small{X}$服从参数为$\small{p}$的几何分布，则记为$\small{X \sim G(p)}$。

    几何分布的期望和方差分别为：
    $$
    \begin{align}
    E(X) &= \frac{1}{p} \\
    V(X) &= \frac{1 - p}{p^2}
    \end{align}
    $$

#### 例子

下面，我们通过一些例子来展示，如何在特定场景下利用上面的概率质量函数完成概率计算。

例1：已知某城市餐饮行业首年的生存率为20%，假设今年有15家餐馆开业，问1年后至少有4家餐馆存活下来的概率是多少？

可以简单评估一下，存活下来的餐馆数量应该是一个二项分布的随机变量。现在已知$\small{n=15, p=0.2}$，我们可以通过下面的公式来计算题目要求的概率：
$$
\begin{align}
P(X \ge 4) &= 1 - P(x \lt 4) \\
&= 1 - \sum_{k=0}^{3}C_{n}^{k}p^{k}(1-p)^{n-k}\\
&= 1 - \sum_{k=0}^{3}C_{15}^{i} \times 0.2^{i} \times 0.8^{15-i} \\
&\approx 1 - 0.6482 \approx 0.3518
\end{align}
$$
> **提示**：使用 Python 语言，可以利用三方库 scipy 的`stats`模块来完成上面的计算，执行`stats.binom.cdf(3, n=15, p=0.2)`可以得到0.6482，其中`cdf`函数是*cumulative distribution function*的缩写，允许我们设定随机变量的值以及二项分布的参数$\small{n}$和$\small{p}$，来计算累积概率分布。

例2：一个赌博游戏，每局获胜的概率是10%，玩家需要玩多少次才能大概率（95%的概率）保证赢一次？（专栏导读中“有趣的概率问题”中的第9题）

题目中的随机变量服从几何分布，如果希望95%的概率获胜一次，也就意味着：
$$
\begin{align}
P(X \le k) &= 1 - P(X \gt k)\\
&= 1 - (1 - p)^{k} \ge 0.95
\end{align}
$$
我们将$\small{p = 0.1}$代入上面的不等式，得到$\small{k \gt 28}$，即玩家需要玩29次才能大概率保证赢一次，这个结果是不是颠覆了你的认知。当然，如果你熟悉 Python 语言， 我们可以通过下面这段简单的代码得到同样的结论。

```python
p = 0.1       # 试验成功的概率
k = 1         # 试验次数
cum_prob = 0  # 累积的概率
while True:
    cum_prob += (1 - p) ** (k - 1) * p
    if cum_prob > 0.95:
        print(f'{k = }')
        break
    k += 1
```

输出：

```
k = 29
```

同理，如果面试获得offer的概率是50%，如果要以95%的概率获得offer，至少需要面试5次。但是，如果我们通过提升自己的综合职业素养，让面试成功获得offer的概率提升到78%，这个时候面试2次就有95%以上的概率能获得offer。就找工作这个事情而言，几何分布告诉我们，成功获得offer的秘密就是要么你得多面试几家公司，要么你得提升自己的综合职业素养，前者得靠自己，后者的话我可以帮到你，这也是我现在正在从事的工作。

> **提示**：使用 Python 语言，可以借助三方库 scipy 的`stats`模块来完成上面的计算，执行`stats.geom.ppf(0.95, 0.1)`可以得到29，其中`ppf`函数是*percent point function*的缩写，允许我们设定累积分布概率和试验成功的概率来获得随机变量的值。

例3：假设一个公司门口有10个停车位，该公司有100名员工上班，每名员工早上8点钟之前开车来上班的概率是10%，这些人每天什么时候来公司是随机的，而且彼此无关，也不存在头一天来晚了没有抢到车位第二天就早到的可能性。问早上8点整开车到了公司，停车场还有车位的概率是多少？（专栏导读中“有趣的概率问题”中的第10题）

按照题目所述，停车场一共有10个车位，那就意味着早上8点以前，只要停车场停车的数量为0到9，8点整开车到公司就是有车位的。停车场在早上8点以前有多少量车是一个服从泊松分布的随机变量，我们令$\small{\lambda = np}$，其中$\small{n}$是员工的数量，$\small{p}$是8点钟以前开车来上班的概率，因此$\small{\lambda = 100 \times 0.1 = 10}$。接下来，我们可以用下面的公式计算出题目中的概率：
$$
\sum_{k=0}^{9}P(X=k) = \sum_{k=0}^{9} \frac{\lambda^{k}}{k!} \cdot e^{-\lambda} = \sum_{k=0}^{9} \frac{10^{k}}{k!} \cdot e^{-10} = 0.4579
$$

> **提示**：使用 Python 语言，可以利用三方库 scipy 的`stats`模块来计算泊松分布的累积概率，执行`stats.poisson.cdf(9, 10)`就可以得到0.4579。

如果我们希望把上面的概率提高到0.9，也就是说早上8点整开车到公司会大概率有车位，停车场需要大规模扩容吗？利用上面的公式，我们可以计算出，在其他条件不变的情况下，当停车场有15个车位时，这个概率就会大于0.9。

### 连续型随机变量的分布

在众多连续型随机变量中，最重要的一种随机变量其概率密度函数呈现铃铛形状。我们把这种随机变量称之为正态随机变量，相应的概率分布称为**正态分布**（*normal distribution*）或**高斯分布**（*Gaussian distribution*）。正态分布经常用于自然科学和社会科学中来代表一个分布不明的随机变量，通常认为，如果一个随机变量的值受到诸多因素的影响，但是每个因素的影响又非常有限，那么该随机变量最终会呈现出正态分布。这一点，从定性的角度可以通过伽尔顿板试验来得到验证，如下图所示。

<img src="res/galton_board.gif" style="zoom:110%;">

伽尔顿板为一块竖直放置的板，上面有交错排列的钉子。让小球从板的上端自由下落，当其碰到钉子后会随机向左或向右落下。最终，小球会落至板底端的某一格子中。假设板上共有$\small{n}$排钉子，每个小球撞击钉子后向右落下的概率为$\small{p}$（如果向左向右的概率相同，$\small{p}$的取值为0.5），那么小球落入下方第$\small{k}$个格子概率服从上面讲过的二项分布，其概率值为$\small{{n \choose k}p^{k}(1-p)^{n-k}}$。此时，将大量小球落至格中，格子中的小球数量将呈现出正态分布的铃铛型曲线。这里，小球落入不同的格子相当于随机变量取到不同的值，而钉子就是影响随机变量值的因素，小球落入哪个格子受到了多行钉子的影响，不管做多少次这样的试验，最终格子中小球的数量都呈现出正态分布的轮廓。

如果随机变量$ X $的概率密度函数为：
$$
f(x)={\frac{1}{{\sqrt{2\pi}\sigma}}}e^{-{\frac{(x-\mu)^{2}}{2\sigma ^{2}}}}
$$
则称$\small{X}$服从正态分布，记为$\small{X \sim N(\mu, \sigma^{2})}$，其中$\small{\mu}$是正态分布的位置参数，它决定了概率密度曲线对称轴的位置；$\small{\sigma}$是正态分布的形状参数，它决定了概率密度曲线的陡缓程度，如下图所示。

<img src="res/normal_distribution.png" style="zoom:35%;">

当正态分布的两个参数$\small{\mu = 0}$，$\small{\sigma=1}$时，有：
$$
f(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
$$
我们将这样的正态分布称为标准正态分布（*standard normal distribution*）。一个普通的正态分布可以通过下面的线性变换转化为标准正态分布，这样的话就可以通过查表的方式解决正态分布的概率计算问题，在计算机技术普及之前，这一点是相当重要的。
$$
Z = \frac{X - \mu}{\sigma} \sim N(0, 1)
$$

<img src="res/z_dist_cheat_sheet.jpg" style="zoom:50%;">

> **说明**：今天由于计算机的普及，上面的标准正态分布速查表就没有那么重要了。如果你使用 Python 语言，可以通过三方库 scipy 中的`stats.norm.pdf`函数计算正态分布的概率。Excel 中，可以通过`NORM.DIST`函数计算正态分布的概率，可以通过`NORM.S.DIST`计算标准正态分布的概率。

根据“棣莫弗-拉普拉斯定理”，假设$\small{\mu_{n} (n=1, 2, \cdots)}$表示$\small{n}$重伯努利试验中成功的次数，已知每次试验成功的概率为$\small{p}$，有：
$$
\lim_{n \to \infty} P\lbrace \frac{\mu_n - np} {\sqrt{np(1-p)}} \le x \rbrace = \frac {1} {\sqrt{2\pi}} \int_{-\infty}^{x} e^{-\frac {t^2} {2}} dt
$$
该定理表明正态分布是二项分布的极限分布，这也是为什么说概率统计是建立在抛硬币试验基础上的最佳佐证。

#### 68-95-99.7法则

提到正态分布，就必须说一下“3$\sigma$法则”，该法则也称为“68-95-99.7法则”，如下图所示。

<img src="res/empirical_rule.png" style="zoom:75%;">

> **说明**：上面两张图也来自于维基百科，很多讲解正态分布的文章和视频都引用了这些图。

对于随机变量$\small{X \sim N(\mu, \sigma^{2})}$，上面的图也可以用下面的公式来表示：
$$
\begin{align}
P(\mu-1\sigma \lt X \lt \mu+1\sigma) &\approx 0.68 \\
P(\mu-2\sigma \lt X \lt \mu+2\sigma) &\approx 0.95 \\
P(\mu-3\sigma \lt X \lt \mu+3\sigma) &\approx 0.997
\end{align}
$$
简单的说，对于一个正态分布的随机变量，几乎所有（99.7%）的值都会在均值（$\small{\mu}$）正负三个标准差（$\small{\sigma}$）的范围内。换句话说，如果我们认为某个数据来自于一个正态总体，那么它的值应该以极大的概率位于$\small{[\mu-3\sigma, \mu+3\sigma]}$范围或以较大概率位于$\small{[\mu-2\sigma, \mu+2\sigma]}$范围。如果数据不在这个范围，我们就有足够的理由怀疑它并非来自于该正态总体，这一点对于我们后面要讲的假设检验非常重要。生产中的质量检验和过程控制也利用了这一思想，有兴趣的读者可以了解一下风靡全球的六西格玛质量管理体系。在这种质量管理体系下，产品的合格率要达到99.9999998%，即残次率仅为十亿分之二；即便考虑到$\small{1.5\sigma}$的漂移（由于随机因素的影响，实际结果偏离理论值的情况），残次率也仅为百万分之3.4，即100万个产品中有缺陷的产品不到4个。

我们再来讲一个大学英语四六级考试的例子，英语四六级考试的成绩并不是你卷面的原始分，而是经过处理之后的标准分。处理的方式是将所有人的考试成绩转化成一个$\small{\mu=500, \sigma=70}$的正态分布，通过这个标准分你就能知道你的成绩在所有考生中所处的位置。很多学校设置的425分的合格线大致位于$\small{\mu-\sigma}$的位置，通过上图可以看出，只要你的成绩大约超过了16%的考生，也就达到了合格的水平。这个要求其实并不高，只是很多人不明白学习英语的重要性，甚至以“爱国”来掩饰自己不重视英语的事实，这才导致了自己连16%这个水平都达不到。当然，每年考试也有不少人的成绩会超过640分，640分位于$\small{\mu+2\sigma}$的位置，虽然这个成绩在很多学霸眼里不算什么，但已经是全国前2.5%的水平。美国纽约有一家对冲基金投资公司，这家公司非常擅长使用人工智能、机器学习、分布式计算等技术手段来进行投资策略的管理，它的名字叫 [Two Sigma](https://www.twosigma.com/)。这家公司的创始人之一大卫·赛格（*David Siegel*）是 MIT 的计算机博士，妥妥的 IT 技术男；而公司的名字据说是为了反映 Sigma 这个词的双重性，小写的$\small{\sigma}$指的是投资回报率相对于给定基准$\small{\mu}$的波动性，而大写的$\small{\Sigma}$是指总的收益。当然，很多人更愿意相信，Two Sigma 这个名字是暗示基金的表现要达到$\small{\mu+2\sigma}$这个水准，也就是近乎“百里挑二”的水平。
